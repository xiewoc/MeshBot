# config/config_loader.py
import json
import logging
from pathlib import Path  

logger = logging.getLogger(__name__)

# é»˜è®¤é…ç½®ï¼ˆä¸å¸¸ä¿®æ”¹çš„éƒ¨åˆ†ï¼‰
DEFAULT_CONFIG = {
    "system": {
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹,è¯·ç”¨ç®€æ´çš„è¯­è¨€(å°äº200å­—ç¬¦)å›å¤ã€‚",
        "max_response_length": 200,
        "message_queue_timeout": 1
    },
    "clients": {
        "ollama": {
            "module": "meshbot.api.ollama_api",
            "class": "AsyncOllamaChatClient",
            "kwargs": {
                "default_model": "qwen2.5:7b"  # ä¼šè¢«ç”¨æˆ·é…ç½®è¦†ç›–
            }
        },
        "openai": {
            "module": "meshbot.api.openai_api",
            "class": "AsyncOpenAIChatClient",
            "kwargs": {
                "api_key": "your-api-key",  # ä¼šè¢«ç”¨æˆ·é…ç½®è¦†ç›–
                "default_model": "gpt-3.5-turbo"  # ä¼šè¢«ç”¨æˆ·é…ç½®è¦†ç›–
            }
        },
        "deepseek": {
            "module": "meshbot.api.deepseek_api",
            "class": "AsyncDeepSeekChatClient",
            "kwargs": {
                "api_key": "your-api-key",  # ä¼šè¢«ç”¨æˆ·é…ç½®è¦†ç›–
                "default_model": "deepseek-chat"  # ä¼šè¢«ç”¨æˆ·é…ç½®è¦†ç›–
            }
        },
        "openrouter": {
            "module": "meshbot.api.openrouter_api",
            "class": "AsyncOpenRouterChatClient",
            "kwargs": {
                "app_name": "MeshBot",
                "api_key": "your-api-key"  # ä¼šè¢«ç”¨æˆ·é…ç½®è¦†ç›–
            }
        },"gemini": {
            "module": "meshbot.api.gemini_api",
            "class": "AsyncGeminiChatClient",
            "kwargs": {
                "api_key": "your-gemini-api-key",
                "default_model": "gemini-pro"
            }
        },
        "claude": {
            "module": "meshbot.api.claude_api",
            "class": "AsyncClaudeChatClient",
            "kwargs": {
                "api_key": "your-claude-api-key",
                "default_model": "claude-3-sonnet-20240229"
            }
        },
        "siliconflow": {
            "module": "meshbot.api.siliconflow_api",
            "class": "AsyncSiliconFlowChatClient",
            "kwargs": {
                "api_key": "your-siliconflow-api-key",
                "default_model": "deepseek-ai/DeepSeek-V2-Chat"
            }
        },
        "websockets": {
            "module": "meshbot.api.ws_platform",
            "class": "AsyncWebSocketsClient",
            "kwargs": {
                "uri": "ws://localhost:9238"  # ä¼šè¢«ç”¨æˆ·é…ç½®è¦†ç›–
            }
        },
        "fastapi": {
            "module": "meshbot.api.fastapi_client",
            "class": "AsyncFastAPIChatClient", 
            "kwargs": {
                "base_url": "http://127.0.0.1:8000",
                "api_key": "your-fastapi-token"  # å¯é€‰
            }
        },
    }
}

# åˆå¹¶åçš„é…ç½®
CONFIG = None
SYSTEM_PROMPT = None
PLATFORM = None
MAX_RESPONSE_LENGTH = None
MESSAGE_QUEUE_TIMEOUT = None
AI_CLIENT_CONFIG = None


def load_config(config_path: str = str((Path(__file__).parent / "../../config.json").resolve())) -> None:
    """ä» JSON æ–‡ä»¶åŠ è½½é…ç½®å¹¶ä¸é»˜è®¤é…ç½®åˆå¹¶"""
    global CONFIG, SYSTEM_PROMPT, PLATFORM, MAX_RESPONSE_LENGTH, MESSAGE_QUEUE_TIMEOUT, AI_CLIENT_CONFIG
    
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            user_config = json.load(f)
    except FileNotFoundError:
        raise RuntimeError("é…ç½®æ–‡ä»¶ config.json æœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨ã€‚")
    except json.JSONDecodeError as e:
        raise RuntimeError(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼š{e}")

    # åˆå¹¶é…ç½®
    CONFIG = _merge_configs(DEFAULT_CONFIG, user_config)
    
    # è§£æç³»ç»Ÿé…ç½®
    SYSTEM_PROMPT = CONFIG["system"]["system_prompt"]
    PLATFORM = user_config.get("platform", "ollama")  # ä»ç”¨æˆ·é…ç½®è·å–å¹³å°
    MAX_RESPONSE_LENGTH = CONFIG["system"]["max_response_length"]
    MESSAGE_QUEUE_TIMEOUT = CONFIG["system"]["message_queue_timeout"]

    # AI å®¢æˆ·ç«¯é…ç½®
    AI_CLIENT_CONFIG = CONFIG["clients"]
    
    logger.info("âœ… é…ç½®åŠ è½½æˆåŠŸ")
    logger.info(f"ğŸ¯ å½“å‰å¹³å°: {PLATFORM}")


def _merge_configs(default_config: dict, user_config: dict) -> dict:
    """æ·±åº¦åˆå¹¶é»˜è®¤é…ç½®å’Œç”¨æˆ·é…ç½®"""
    result = default_config.copy()
    
    # å¤„ç† API keys
    if "api_keys" in user_config:
        for platform, api_key in user_config["api_keys"].items():
            if platform in result["clients"] and api_key != "your-api-key":
                if "kwargs" in result["clients"][platform]:
                    result["clients"][platform]["kwargs"]["api_key"] = api_key
    
    # å¤„ç†æ¨¡å‹è®¾ç½®
    if "model_settings" in user_config:
        for platform, model in user_config["model_settings"].items():
            if platform in result["clients"]:
                if "kwargs" in result["clients"][platform]:
                    result["clients"][platform]["kwargs"]["default_model"] = model
    
    # å¤„ç†æœåŠ¡ URLs
    if "service_urls" in user_config:
        # WebSocket
        ws_url = user_config["service_urls"].get("websockets")
        if ws_url and ws_url != "ws://localhost:9238" and "websockets" in result["clients"]:
            result["clients"]["websockets"]["kwargs"]["uri"] = ws_url
            
        # FastAPI
        fastapi_url = user_config["service_urls"].get("fastapi") 
        if fastapi_url and fastapi_url != "http://127.0.0.1:8000" and "fastapi" in result["clients"]:
            result["clients"]["fastapi"]["kwargs"]["base_url"] = fastapi_url
      
    # å¤„ç†ç³»ç»Ÿæç¤ºï¼ˆå¯é€‰ï¼Œå¦‚æœç”¨æˆ·æƒ³è¦è‡ªå®šä¹‰ï¼‰
    if "system_prompt" in user_config:
        result["system"]["system_prompt"] = user_config["system_prompt"]
    
    return result


def get_ai_client_config():
    """è·å– AI å®¢æˆ·ç«¯é…ç½®"""
    if AI_CLIENT_CONFIG is None:
        raise RuntimeError("é…ç½®æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_config()")
    return AI_CLIENT_CONFIG


def get_platform():
    """è·å–å¹³å°é…ç½®"""
    if PLATFORM is None:
        raise RuntimeError("é…ç½®æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_config()")
    return PLATFORM


def get_system_prompt():
    """è·å–ç³»ç»Ÿæç¤º"""
    if SYSTEM_PROMPT is None:
        raise RuntimeError("é…ç½®æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_config()")
    return SYSTEM_PROMPT


def get_max_response_length():
    """è·å–æœ€å¤§å“åº”é•¿åº¦"""
    if MAX_RESPONSE_LENGTH is None:
        raise RuntimeError("é…ç½®æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_config()")
    return MAX_RESPONSE_LENGTH


def get_message_queue_timeout():
    """è·å–æ¶ˆæ¯é˜Ÿåˆ—è¶…æ—¶æ—¶é—´"""
    if MESSAGE_QUEUE_TIMEOUT is None:
        raise RuntimeError("é…ç½®æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_config()")
    return MESSAGE_QUEUE_TIMEOUT


def create_example_config():
    """åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶"""
    example_config = {
        "platform": "ollama",
        "api_keys": {
            "openai": "your-openai-api-key",
            "deepseek": "your-deepseek-api-key",
            "openrouter": "your-openrouter-api-key",
            "gemini": "your-gemini-api-key",
            "claude": "your-claude-api-key",
            "siliconflow": "your-siliconflow-api-key",
            "fastapi": "your-fastapi-token"
        },
        "model_settings": {
            "ollama": "qwen2.5:7b",
            "openai": "gpt-3.5-turbo",
            "deepseek": "deepseek-chat",
            "openrouter": "openai/gpt-3.5-turbo",
            "gemini": "gemini-pro",
            "claude": "claude-3-sonnet-20240229",
            "siliconflow": "deepseek-ai/DeepSeek-V2-Chat",
            "fastapi": "fastapi-default"
        },
        "service_urls": {
            "websockets": "ws://localhost:9238",
            "fastapi": "http://127.0.0.1:8000"
        }
    }
    
    with open("config.json", "w", encoding="utf-8") as f:
        json.dump(example_config, f, indent=2, ensure_ascii=False)
    
    logger.info("ğŸ“ ç¤ºä¾‹é…ç½®æ–‡ä»¶ config.json å·²åˆ›å»º")